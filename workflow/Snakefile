configfile: "config/test.yaml" # test

workdir: config['workdir']

log_prefix = config["log_prefix"]
temp_prefix = config["temp_prefix"]

max_threads = config["max_threads"]
seed = config["seed"]

genome = config["genome"]

atac_samples = config["fastq"].keys()

def get_input_fastq_r1(wildcards):
    return config["fastq"][wildcards.sample]["R1"]

def get_input_fastq_r2(wildcards):
    return config["fastq"][wildcards.sample]["R2"]

def get_input_fastq_bc(wildcards):
    return config["fastq"][wildcards.sample]["BC"]

def sh_command(script_name):
    return "bash " + str(workflow.source_path(script_name))


rule all:
    input:
        "archr_build/indicator.txt",
        expand("align/{sample}/frac_mito.qc", sample=config["fastq"])

"""
Barcode Correction and Filtering
"""
rule barcode_corr:
    input:
        fastq1=get_input_fastq_r1,
        fastq2=get_input_fastq_r2,
        fastq_bc=get_input_fastq_bc,
        bc_whitelist=config["barcode_correction"]["whitelist"] 
    output:
        fastq1_bc="barcode/{sample}_R1_bc.fastq",
        fastq2_bc="barcode/{sample}_R2_bc.fastq",
        qc_barcode_corr="barcode/{sample}_barcode_corr.qc"
    params:
        max_barcode_dist=config["barcode_correction"]["max_barcode_dist"] 
    threads:
        max_threads
    conda:
        "envs/barcode_corr.yaml"
    script:
        "scripts/process_10x_barcodes.py"

"""
Read alignment (Bowtie2 aligner)
"""
rule align_bowtie2:
    input:
        fastq1="barcode/{sample}_R1_bc.fastq",
        fastq2="barcode/{sample}_R2_bc.fastq",
    output:
        bam_raw="align/{sample}/raw.bam",
        bam_raw_ind="align/{sample}/raw.bam.bai",
        bam_no_mito="align/{sample}/non_mito.bam",
        bam_mito="align/{sample}/mito.bam",
        flagstat_qc="align/{sample}/flagstat_raw.qc"
    params:
        multimapping=config["bwt2"]["multimapping"],
        bwt2_idx=config["bwt2"]["index"]
    log:
        log_prefix + "align/{sample}/bwt2.log",
    threads:
        max_threads
    conda:
        "envs/align_bowtie2.yaml"
    shell:
        sh_command("scripts/align.sh") + ""
        " {input.fastq1} {input.fastq2}" 
        " {params.bwt2_idx} {params.multimapping}" 
        " {output.bam_raw} {output.bam_no_mito} {output.bam_mito} {output.flagstat_qc}"
        " {log} {threads}"

"""
Compute fraction of mitochondrial reads
"""
rule frac_mito:
    input:
        bam_raw="align/{sample}/raw.bam",
        bam_mito="align/{sample}/mito.bam",
        bam_no_mito="align/{sample}/non_mito.bam",
    output:
        qc_samstats_mito="align/{sample}/mito_samstats.qc",
        qc_samstats_no_mito="align/{sample}/non_mito_samstats.qc",
        qc_frac_mito="align/{sample}/frac_mito.qc"
    log:
        log_prefix + "align/{sample}/frac_mito.log"
    threads:
        max_threads
    conda:
        "envs/frac_mito.yaml"
    script:
        "scripts/frac_mito.py"

"""
Post-alignment filtering
"""
rule dedup_bam:
    input:
        "align/{sample}/raw.bam"
    output:
        bam="filter/{sample}/final.bam",
        ind="filter/{sample}/final.bam.bai",
        flagstat="filter/{sample}/flagstat_final.qc",
        dup="filter/{sample}/dup.qc",
        pbc="filter/{sample}/pbc.qc",
        filter_temp_prefix=temp(directory(temp_prefix + "filter/tmp_{sample}/"))
    params:
        multimapping=config["bwt2"]["multimapping"],
        mmp_path=str(workflow.source_path("scripts/assign_multimappers.py"))
    threads:
        max_threads
    conda:
        "envs/dedup_bam.yaml"
    shell:
        sh_command("scripts/dedup_bam_pe.sh") + ""
        " {input} {output.bam} {output.ind} {output.flagstat} {output.dup} {output.pbc} {output.filter_temp_prefix}"
        " {params.multimapping} {params.mmp_path} {threads}"

"""
Convert BAM to fragment file
"""
rule bam_to_frag: 
    input:
        bam="filter/{sample}/final.bam",
        bam_ind="filter/{sample}/final.bam.bai",
    output:
        frag="fragment/{sample}_fragments.tsv.gz",
        frag_ind="fragment/{sample}_fragments.tsv.gz.tbi",
        tmp_frag=temp(temp_prefix + "fragment/{sample}/bam_to_frag.tmp"),
    threads:
        max_threads
    conda:
        "envs/bam_to_frag.yaml"
    shell:
        sh_command("scripts/bam_to_frag.sh") + " {input.bam} {output.frag} {output.tmp_frag}"

"""
Preliminary ArchR analyses
"""
rule archr_build:
    input:
        fragments=expand("fragment/{sample}_fragments.tsv.gz", sample=config["fastq"])
    output:
        arrows_temp_dir=temp(directory(temp_prefix + "archr_build/arrows_init")),
        qc_dir=directory("archr_build/qc"),
        project_dir=directory("archr_build/project"),
        indicator=("archr_build/indicator.txt")
    params:
        sample_names=atac_samples,
        seed=seed,
        genome=genome
    log:
        log_dir=(log_prefix + "archr_build"),
        arrow_create=(log_prefix + "archr_build/arrow_create.log"),
        doublets=(log_prefix + "archr_build/doublets.log"),
        lsi=(log_prefix + "archr_build/lsi.log"),
        cluster=(log_prefix + "archr_build/cluster.log"),
        marker_genes=(log_prefix + "archr_build/marker_genes.log"),
        pseudobulk_rep=(log_prefix + "archr_build/pseudobulk_rep.log"),
        peak_call=(log_prefix + "archr_build/peak_call.log"),
        peak_matrix=(log_prefix + "archr_build/peak_matrix.log"),
        marker_peaks=(log_prefix + "archr_build/marker_peaks.log"),
        fetch_motif=(log_prefix + "archr_build/fetch_motif.log"),
        enr_motif=(log_prefix + "archr_build/enr_motif.log"),
        fetch_tf=(log_prefix + "archr_build/fetch_tf.log"),
        enr_tf=(log_prefix + "archr_build/enr_tf.log"),
        save=(log_prefix + "archr_build/save.log"),
    threads:
        max_threads
    conda:
        "envs/archr_build.yaml"
    script:
        "scripts/build_archr_project.R"