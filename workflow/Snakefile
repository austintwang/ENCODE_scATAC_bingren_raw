configfile: "config/test.yaml" # test

workdir: config['workdir']

log_prefix = config["log_prefix"]
temp_prefix = config["temp_prefix"]

max_threads = config["max_threads"]
seed = config["seed"]

genome = config["genome"]

atac_samples = config["fastq"].keys()

def get_input_fastq(wildcards):
    return config["fastq"][wildcards.sample][wildcards.read]

def get_fastq_set_fetcher(path_template):
    def fastq_set_fetcher(wildcards):
        a = expand(path_template, read=config["fastq"][wildcards.sample].keys())
        print(a) ####
        print(config["fastq"][wildcards.sample].keys()) ####
        return a
    return fastq_set_fetcher

def get_fastq_keys(wildcards):
    return config["fastq"][wildcards.sample].keys()

def sh_command(script_name):
    return "bash " + str(workflow.source_path(script_name))


rule all:
    input:
        expand("align/{sample}/frac_mito.qc", sample=config["fastq"]),
        expand("fragment/{sample}_fragments.tar", sample=config["fastq"]),
        "archr_build/indicator.txt"


"""
Strip FASTQ header descriptions
"""
rule strip_fastq:
    input:
        get_input_fastq 
    output:
        "barcode/{sample}/{read}.fastq.gz"
    conda:
        "envs/strip_fastq.yaml"
    shell:
        "zcat {input} | sed 's/ .*//' | gzip -c > {output}"

"""
Barcode correction and filtering
"""
rule barcode_corr:
    input:
        # fastq=get_fastq_set_fetcher("barcode/{sample}/{read}.fastq.gz"),
        whitelist=config["barcode_correction"]["whitelist"].values()
    output:
        fastq1_bc="barcode/{sample}/R1_bc.fastq.gz",
        fastq2_bc="barcode/{sample}/R2_bc.fastq.gz",
        qc_barcode_corr="barcode/{sample}/barcode_corr.qc"
    params:
        max_barcode_dist=config["barcode_correction"]["max_barcode_dist"],
        technology=config["technology"],
        fastq_names=get_fastq_keys,
        whitelist_names=config["barcode_correction"]["whitelist"].keys()
    threads:
        max_threads
    conda:
        "envs/barcode_corr.yaml"
    script:
        "scripts/process_10x_barcodes_matcha.py"

"""
Read adapter trimming
"""
rule trim_adapter:
    input:
        fastq1_bc="barcode/{sample}/R1_bc.fastq.gz",
        fastq2_bc="barcode/{sample}/R2_bc.fastq.gz",
    output:
        fastq1_trim="barcode/{sample}/R1_trim.fastq.gz",
        fastq2_trim="barcode/{sample}/R2_trim.fastq.gz",
        qc_html="barcode/{sample}/fastp_qc.html",
        qc_json="barcode/{sample}/fastp_qc.json",
    params:
        max_barcode_dist=config["barcode_correction"]["max_barcode_dist"] 
    threads:
        max_threads
    conda:
        "envs/trim_adapter.yaml"
    shell:
        "fastp -i {input.fastq1_bc} -I {input.fastq2_bc} -o {output.fastq1_trim} -O {output.fastq2_trim}"
        " -h {output.qc_html} -j {output.qc_json} -G -Q -L -w {threads}"

"""
Read alignment (Bowtie2 aligner)
"""
rule align_bowtie2:
    input:
        fastq1="barcode/{sample}/R1_trim.fastq.gz",
        fastq2="barcode/{sample}/R2_trim.fastq.gz",
    output:
        bam_raw="align/{sample}/raw.bam",
        bam_raw_ind="align/{sample}/raw.bam.bai",
        bam_no_mito="align/{sample}/non_mito.bam",
        bam_mito="align/{sample}/mito.bam",
        flagstat_qc="align/{sample}/flagstat_raw.qc"
    params:
        multimapping=config["bwt2"]["multimapping"],
        bwt2_idx=config["bwt2"]["index"]
    log:
        log_prefix + "align/{sample}/bwt2.log",
    threads:
        max_threads
    conda:
        "envs/align_bowtie2.yaml"
    shadow: 
        "minimal"
    shell:
        sh_command("scripts/align.sh") + ""
        " {input.fastq1} {input.fastq2}" 
        " {params.bwt2_idx} {params.multimapping}" 
        " {output.bam_raw} {output.bam_no_mito} {output.bam_mito} {output.flagstat_qc}"
        " {log} {threads}"

"""
Compute fraction of mitochondrial reads
"""
rule frac_mito:
    input:
        bam_raw="align/{sample}/raw.bam",
        bam_mito="align/{sample}/mito.bam",
        bam_no_mito="align/{sample}/non_mito.bam",
    output:
        qc_samstats_mito="align/{sample}/mito_samstats.qc",
        qc_samstats_no_mito="align/{sample}/non_mito_samstats.qc",
        qc_frac_mito="align/{sample}/frac_mito.qc"
    log:
        log_prefix + "align/{sample}/frac_mito.log"
    threads:
        max_threads
    conda:
        "envs/frac_mito.yaml"
    shadow: 
        "minimal"
    script:
        "scripts/frac_mito.py"

"""
Post-alignment filtering
"""
rule dedup_bam:
    input:
        "align/{sample}/raw.bam"
    output:
        bam="filter/{sample}/final.bam",
        ind="filter/{sample}/final.bam.bai",
        flagstat="filter/{sample}/flagstat_final.qc",
        dup="filter/{sample}/dup.qc",
        pbc="filter/{sample}/pbc.qc",
        filter_temp_prefix=temp(directory(temp_prefix + "filter/tmp_{sample}/"))
    params:
        multimapping=config["bwt2"]["multimapping"],
        mmp_path=str(workflow.source_path("scripts/assign_multimappers.py"))
    threads:
        max_threads
    conda:
        "envs/dedup_bam.yaml"
    shadow: 
        "minimal"
    shell:
        sh_command("scripts/dedup_bam_pe.sh") + ""
        " {input} {output.bam} {output.ind} {output.flagstat} {output.dup} {output.pbc} {output.filter_temp_prefix}"
        " {params.multimapping} {params.mmp_path} {threads}"

"""
Convert BAM to fragment file
"""
rule bam_to_frag: 
    input:
        bam="filter/{sample}/final.bam",
        bam_ind="filter/{sample}/final.bam.bai",
    output:
        frag="fragment/{sample}_fragments.tsv.gz",
        frag_ind="fragment/{sample}_fragments.tsv.gz.tbi",
        tmp_frag=temp(temp_prefix + "fragment/{sample}/bam_to_frag.tmp"),
    threads:
        max_threads
    conda:
        "envs/bam_to_frag.yaml"
    shadow: 
        "minimal"
    shell:
        sh_command("scripts/bam_to_frag.sh") + " {input.bam} {output.frag} {output.tmp_frag}"

"""
Package fragment file into tarball
"""
rule frag_tar: 
    input:
        frag="fragment/{sample}_fragments.tsv.gz",
        frag_ind="fragment/{sample}_fragments.tsv.gz.tbi",
    output:
        "fragment/{sample}_fragments.tar",
    conda:
        "envs/frag_tar.yaml"
    shell:
        "tar -cvf {output} {input.frag} {input.frag_ind}"

"""
Preliminary ArchR analyses
"""
rule archr_build:
    input:
        frag=expand("fragment/{sample}_fragments.tsv.gz", sample=config["fastq"]),
        frag_ind=expand("fragment/{sample}_fragments.tsv.gz.tbi", sample=config["fastq"]),
    output:
        arrows_temp_dir=temp(directory(temp_prefix + "archr_build/arrows_init")),
        qc_dir=directory("archr_build/qc"),
        project_dir=directory("archr_build/project"),
        indicator=touch("archr_build/indicator.txt")
    params:
        sample_names=atac_samples,
        seed=seed,
        genome=genome
    log:
        log_dir=(log_prefix + "archr_build"),
        arrow_create=(log_prefix + "archr_build/arrow_create.log"),
        doublets=(log_prefix + "archr_build/doublets.log"),
        lsi=(log_prefix + "archr_build/lsi.log"),
        cluster=(log_prefix + "archr_build/cluster.log"),
        marker_genes=(log_prefix + "archr_build/marker_genes.log"),
        pseudobulk_rep=(log_prefix + "archr_build/pseudobulk_rep.log"),
        peak_call=(log_prefix + "archr_build/peak_call.log"),
        peak_matrix=(log_prefix + "archr_build/peak_matrix.log"),
        marker_peaks=(log_prefix + "archr_build/marker_peaks.log"),
        fetch_motif=(log_prefix + "archr_build/fetch_motif.log"),
        enr_motif=(log_prefix + "archr_build/enr_motif.log"),
        fetch_tf=(log_prefix + "archr_build/fetch_tf.log"),
        enr_tf=(log_prefix + "archr_build/enr_tf.log"),
        save=(log_prefix + "archr_build/save.log"),
    threads:
        max_threads
    conda:
        "envs/archr_build.yaml"
    shadow: 
        "minimal"
    script:
        "scripts/build_archr_project.R"